\subsection*{Benefits}
\begin{itemize}
  \item \textbf{Reduced refresh overhead:} Part of the dataset can be parked in FeRAM, cutting DRAM refresh traffic and standby power.
  \item \textbf{Fast persistence:} System state can be checkpointed to FeRAM with microsecond-scale latency, enabling quick resume.
  \item \textbf{Data resilience:} FeRAM provides crash consistency for critical metadata and write-back buffers.
\end{itemize}

\subsection*{Constraints and trade-offs}
\begin{itemize}
  \item \textbf{Endurance and variability:} FeRAM endurance ($10^{12}$--$10^{13}$ cycles) is high but still below DRAM refresh activity.
  \item \textbf{Write energy and latency:} FeRAM generally incurs higher write energy than DRAM; policies should bias read-mostly or cold data to FeRAM.
  \item \textbf{Integration cost:} Adding FeFET or ferroelectric layers in advanced CMOS nodes introduces process-compatibility and reliability risks (e.g., TDDB under high fields).
\end{itemize}

\subsection*{System design directions}
\begin{itemize}
  \item \textbf{Tiering policies:} Classify pages/objects by write intensity and retention needs, migrating cold or persistent data to FeRAM.
  \item \textbf{Refresh co-optimization:} Dynamically shrink DRAM refresh for regions shadowed or backed by FeRAM.
  \item \textbf{Checkpoint and logging:} Exploit FeRAM bandwidth for low-latency state persistence.
  \item \textbf{Controller support:} Keep metadata for wear leveling, retention-aware placement, and error monitoring (e.g., soft/hard failure counters).
\end{itemize}
